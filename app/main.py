import threading
import time
import asyncio
import concurrent.futures
from fastapi import FastAPI, BackgroundTasks
import numpy as np
import pandas as pd
import tensorflow as tf
import os

from .lib.core.predict import predict, get_top_popular_products
from .lib.core.train import train_model
from .lib.core.data_manager import DataManager
from .paths import MODEL_PATH, CACHE_DELETED_ITEM_PATH, CACHE_USER_PATH, CACHE_ITEM_PATH, CACHE_INTERACTION_PATH

app = FastAPI()
data_manager = DataManager()

# Thread pool for CPU-intensive prediction tasks
prediction_executor = concurrent.futures.ThreadPoolExecutor(
    max_workers=6,  # TƒÉng t·ª´ 4 l√™n 6 ƒë·ªÉ x·ª≠ l√Ω 3 users ƒë·ªìng th·ªùi t·ªët h∆°n
    thread_name_prefix="prediction-worker"
)

# Rate limiting ƒë·ªÉ tr√°nh overload
from collections import defaultdict
request_counts = defaultdict(int)
request_timestamps = defaultdict(list)

def check_rate_limit(user_id: str, max_requests: int = 10, window_seconds: int = 60):
    """Simple rate limiting per user"""
    current_time = time.time()
    user_timestamps = request_timestamps[user_id]
    
    # Remove old timestamps outside the window
    user_timestamps[:] = [ts for ts in user_timestamps if current_time - ts < window_seconds]
    
    if len(user_timestamps) >= max_requests:
        return False
    
    user_timestamps.append(current_time)
    return True

@app.get("/")
def read_root():
    return {"Hello": "World"}

@app.get("/recommend")
async def recommend(uid: str, max: int):
    request_start_time = time.time()
    print(f"üîÑ User {uid} request started in thread {threading.current_thread().name}")
    
    try:
        # Rate limiting check
        if not check_rate_limit(uid):
            return {"error": "Rate limit exceeded", "products": []}
        
        # Thread-safe data loading check v·ªõi proper locking
        async def ensure_data_loaded():
            # Check nhanh tr∆∞·ªõc khi acquire lock ƒë·ªÉ tr√°nh blocking kh√¥ng c·∫ßn thi·∫øt
            if data_manager.data is not None:
                return
                
            # Acquire initialization lock ƒë·ªÉ ƒë·∫£m b·∫£o ch·ªâ 1 thread load data
            with data_manager.init_lock:
                # Double-check locking pattern
                if data_manager.data is None and not data_manager.is_initializing:
                    data_manager.is_initializing = True
                    try:
                        print(f"Thread {threading.current_thread().name}: Loading data...")
                        await data_manager.load_data()
                        data_manager.preprocess_data()
                        print(f"Thread {threading.current_thread().name}: Data loading completed")
                    finally:
                        data_manager.is_initializing = False
                elif data_manager.is_initializing:
                    # N·∫øu thread kh√°c ƒëang load, ch·ªù cho ƒë·∫øn khi ho√†n th√†nh
                    print(f"Thread {threading.current_thread().name}: Waiting for data loading to complete...")
                    while data_manager.is_initializing:
                        await asyncio.sleep(0.1)  # Ch·ªù 100ms r·ªìi check l·∫°i
            
        await ensure_data_loaded()
            
        recommendations = []
        
        # Thread-safe data access v·ªõi read lock
        with data_manager.data_lock:
            if data_manager.data is None:
                raise ValueError("Data not available after loading attempt")
            product_ids = data_manager.get_product_ids()
            
        top_k = min(max, len(product_ids))        # Use thread pool executor for concurrent prediction
        loop = asyncio.get_running_loop()
        futures = [
            loop.run_in_executor(prediction_executor, predict, uid, product_id)
            for product_id in product_ids
        ]
        
        # Wait for all predictions to complete
        results = await asyncio.gather(*futures, return_exceptions=True)
        
        # Process results
        for i, result in enumerate(results):
            product_id = product_ids[i]
            try:
                if isinstance(result, Exception):
                    print(f"Error predicting for product {product_id}: {result}")
                    continue
                
                score = result
                if score >= 0:  # Ch·ªâ l·∫•y nh·ªØng d·ª± ƒëo√°n h·ª£p l·ªá
                    recommendations.append((product_id, score))
            except Exception as e:
                print(f"Error processing result for product {product_id}: {e}")
                continue
        
        # S·∫Øp x·∫øp theo x√°c su·∫•t cao nh·∫•t
        recommendations.sort(key=lambda x: x[1], reverse=True)
        
        # L·∫•y top k s·∫£n ph·∫©m
        top_products = [prod[0] for prod in recommendations[:top_k]]
        
        # N·∫øu ch∆∞a ƒë·ªß k s·∫£n ph·∫©m, l·∫•y c√°c s·∫£n ph·∫©m ph·ªï bi·∫øn nh·∫•t
        if len(top_products) < top_k:
            try:
                popular_products = get_top_popular_products(top_k - len(top_products))
                # Lo·∫°i b·ªè duplicate
                for prod in popular_products:
                    if prod not in top_products and len(top_products) < top_k:
                        top_products.append(prod)
            except Exception as e:                print(f"Error getting popular products: {e}")

        print(f"‚úÖ User {uid} completed in {time.time() - request_start_time:.2f}s - thread {threading.current_thread().name}")
        print(f"üìä Found {len(recommendations)} recommendations, returning top {len(top_products)} products")
        return {
            "products": top_products, 
            "total_found": len(recommendations),
            "processing_time": round(time.time() - request_start_time, 2),
            "thread_id": threading.current_thread().name
        }
    except Exception as e:
        print(f"Error in recommend endpoint: {e}")
        return {"error": str(e), "products": []}

@app.post("/build")
async def build():
    print("Building!")
    try:
        # Thread-safe data loading v·ªõi proper locking
        async def ensure_data_loaded():
            if data_manager.data is not None:
                return
                
            with data_manager.init_lock:
                if data_manager.data is None and not data_manager.is_initializing:
                    data_manager.is_initializing = True
                    try:
                        await data_manager.load_data()
                        data_manager.preprocess_data()
                    finally:
                        data_manager.is_initializing = False
                elif data_manager.is_initializing:
                    while data_manager.is_initializing:
                        await asyncio.sleep(0.1)
        
        await ensure_data_loaded()
            
        train_model()
        print("Build done!")
        return {"message": "Build successfully"}
    except Exception as e:
        print("Build failed with error: ")
        print(e)
        return {"message": str(e), "error": True}


# H√†m build l·∫°i model theo chu k·ª≥
def periodic_train_model(interval, model_rebuild_function):
    """
    X√¢y d·ª±ng l·∫°i m√¥ h√¨nh theo chu k·ª≥.

    Args:
        interval (int): Chu k·ª≥ t√≠nh theo gi√¢y ƒë·ªÉ ch·ªù x√¢y d·ª±ng l·∫°i m√¥ h√¨nh.
        model_rebuild_function (function): H√†m build l·∫°i m√¥ h√¨nh
    """
    while True:
        # Ghi l·∫°i th·ªùi gian b·∫Øt ƒë·∫ßu
        start_time = time.time()

        print("Rebuilding model...")
        model_rebuild_function()
        
        # Ghi l·∫°i th·ªùi gian k·∫øt th√∫c
        end_time = time.time()
        
        # T√≠nh to√°n th·ªùi gian th·ª±c thi
        execution_time = end_time - start_time

        print(f"Model rebuild completed [{execution_time:.4f} seconds]. Waiting for next cycle...")
        
        time.sleep(interval)


@app.on_event("startup")
async def init():
    try:
        print("Starting up application...")
        await data_manager.load_data(True)
        data_manager.preprocess_data()
        data_manager.start_streams()
        os.environ["TF_DATA_AUTOTUNE_RAM_budget"] = "104857600"  # 100 MB
        print("Application startup completed!")
    except Exception as e:
        print(f"Error during startup: {e}")
        # Kh√¥ng raise exception ƒë·ªÉ app v·∫´n c√≥ th·ªÉ start, nh∆∞ng log l·ªói

@app.get("/health")
async def health_check():
    """Health check endpoint to verify system status."""
    try:
        status = {
            "status": "healthy",
            "data_loaded": data_manager.data is not None,
            "model_available": True,  # We'll check this when model manager is available
            "thread_id": threading.current_thread().name,
            "timestamp": time.time()
        }
        
        # Quick data validation
        if data_manager.data is not None:
            with data_manager.data_lock:
                status["data_records"] = len(data_manager.data)
                status["product_count"] = len(data_manager.data["product_id"].unique())
        else:
            status["data_records"] = 0
            status["product_count"] = 0
            
        return status
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "thread_id": threading.current_thread().name,
            "timestamp": time.time()
        }

@app.get("/test-concurrent")
async def test_concurrent_requests():
    """Test endpoint ƒë·ªÉ ki·ªÉm tra kh·∫£ nƒÉng x·ª≠ l√Ω concurrent requests"""
    try:
        # Test v·ªõi 3 users kh√°c nhau b·∫±ng c√°ch g·ªçi tr·ª±c ti·∫øp function
        test_users = ["U001", "U002", "U003"]
        max_products = 5
        
        async def simulate_user_request(user_id):
            """M√¥ ph·ªèng m·ªôt request t·ª´ user"""
            start_time = time.time()
            try:
                # G·ªçi tr·ª±c ti·∫øp function recommend
                result = await recommend(user_id, max_products)
                duration = time.time() - start_time
                
                return {
                    "user_id": user_id,
                    "status": "success" if "products" in result else "error",
                    "duration": round(duration, 2),
                    "products_count": len(result.get("products", [])),
                    "thread_id": result.get("thread_id", "unknown"),
                    "processing_time": result.get("processing_time", 0)
                }
            except Exception as e:
                return {
                    "user_id": user_id,
                    "status": "error",
                    "duration": round(time.time() - start_time, 2),
                    "error": str(e)
                }
        
        print("üöÄ Starting concurrent test with 3 users...")
        start_time = time.time()
        
        # Ch·∫°y 3 requests ƒë·ªìng th·ªùi
        tasks = [simulate_user_request(user_id) for user_id in test_users]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        total_time = time.time() - start_time
        
        # X·ª≠ l√Ω k·∫øt qu·∫£
        success_count = sum(1 for r in results if isinstance(r, dict) and r.get("status") == "success")
        avg_duration = sum(r.get("duration", 0) for r in results if isinstance(r, dict)) / len(results)
        
        print(f"‚úÖ Concurrent test completed: {success_count}/{len(test_users)} successful in {total_time:.2f}s")
        
        return {
            "test_type": "concurrent_requests",
            "total_users": len(test_users),
            "successful_requests": success_count,
            "total_time": round(total_time, 2),
            "average_request_time": round(avg_duration, 2),
            "results": results,
            "summary": f"‚úÖ {success_count}/{len(test_users)} requests successful in {total_time:.2f}s",
            "concurrent_efficiency": round((avg_duration / total_time) * 100, 1) if total_time > 0 else 0
        }
        
    except Exception as e:
        return {
            "test_type": "concurrent_requests",
            "error": str(e),
            "status": "failed"
        }